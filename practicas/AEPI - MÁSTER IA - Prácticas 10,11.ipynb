{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e63c1ee",
   "metadata": {},
   "source": [
    "# Reconocimiento de imágenes\n",
    "\n",
    "Reconocimiento de fotografías de las caras de 'Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',       'Gerhard Schroeder', 'Hugo Chavez' y 'Tony Blair'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f657cb",
   "metadata": {},
   "source": [
    "El conjunto de datos utilizado en esta práctica es un extracto preprocesado de las *Labeled Faces in the Wild*, también conocido como LFW:\n",
    "\n",
    "http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Se puede descargar directamente de http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (Al pulsar el link, se descargan 233 MB de datos)\n",
    "\n",
    "También se encuentra disponible entre los datasets que incorpora la librería ***Scikit Learn***, por lo que ***para esta práctica se descargarán fácilmente haciendo uso del cargador de datos de esta librería (fetch_lfw_people()***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2767b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports de librerías y módulos necesarios (completar)\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra del progreso de cada salida\n",
    "logging.basicConfig(level = logging.INFO, format = '%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1cae32",
   "metadata": {},
   "source": [
    "En primer lugar, vamos a descargar los datos, si aún no están en el disco, cargándolos como matrices numpy. El conjunto de datos extraído solo conservará imágenes de personas que tengan al menos 70 imágenes diferentes (lo que podemos especificar mediante *min_faces_per_person*) y se utilizará un ratio de 0.4 para cambiar el tamaño de la imagen de cada cara (*resize*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1fa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar los datos y cargarlos como matrices numpy\n",
    "# Almacenarlos en una variable llamada lfw_people\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f8928",
   "metadata": {},
   "source": [
    "El resultado debe ser el siguiente diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff3f9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[254.33333 , 254.      , 252.      , ...,  87.      ,  88.666664,\n",
       "          87.      ],\n",
       "        [ 39.      ,  50.666668,  47.      , ..., 117.666664, 115.      ,\n",
       "         133.      ],\n",
       "        [ 89.666664, 103.666664, 126.333336, ..., 175.33333 , 183.33333 ,\n",
       "         182.66667 ],\n",
       "        ...,\n",
       "        [ 86.666664,  80.      ,  74.333336, ...,  44.333332,  50.      ,\n",
       "          44.666668],\n",
       "        [ 50.666668,  65.333336,  88.333336, ..., 196.66667 , 178.66667 ,\n",
       "         165.66667 ],\n",
       "        [ 30.      ,  27.      ,  33.      , ...,  35.      ,  35.666668,\n",
       "          61.      ]], dtype=float32),\n",
       " 'images': array([[[254.33333 , 254.      , 252.      , ...,  65.666664,\n",
       "           51.333332,  40.333332],\n",
       "         [253.33333 , 251.66667 , 247.66667 , ...,  66.666664,\n",
       "           52.      ,  42.333332],\n",
       "         [240.66667 , 231.33333 , 211.66667 , ...,  61.333332,\n",
       "           49.      ,  41.666668],\n",
       "         ...,\n",
       "         [ 74.333336,  53.666668,  31.333334, ...,  97.333336,\n",
       "           92.666664,  90.      ],\n",
       "         [ 66.      ,  47.333332,  30.333334, ...,  91.666664,\n",
       "           92.      ,  86.333336],\n",
       "         [ 59.      ,  44.666668,  32.333332, ...,  87.      ,\n",
       "           88.666664,  87.      ]],\n",
       " \n",
       "        [[ 39.      ,  50.666668,  47.      , ...,  61.333332,\n",
       "           51.      ,  38.666668],\n",
       "         [ 47.666668,  63.      ,  65.      , ...,  58.333332,\n",
       "           55.333332,  45.      ],\n",
       "         [ 56.      ,  76.      ,  86.333336, ...,  71.      ,\n",
       "           48.666668,  43.666668],\n",
       "         ...,\n",
       "         [ 73.666664,  75.333336,  75.333336, ..., 125.666664,\n",
       "          119.666664, 116.      ],\n",
       "         [ 75.333336,  75.666664,  76.666664, ..., 124.333336,\n",
       "          116.      , 116.666664],\n",
       "         [ 77.333336,  76.      ,  75.666664, ..., 117.666664,\n",
       "          115.      , 133.      ]],\n",
       " \n",
       "        [[ 89.666664, 103.666664, 126.333336, ..., 149.66667 ,\n",
       "          150.66667 , 148.33333 ],\n",
       "         [100.666664, 128.33333 , 143.66667 , ..., 159.      ,\n",
       "          151.33333 , 147.33333 ],\n",
       "         [124.      , 142.66667 , 146.33333 , ..., 161.33333 ,\n",
       "          152.33333 , 147.33333 ],\n",
       "         ...,\n",
       "         [ 75.666664,  73.666664,  74.      , ..., 123.      ,\n",
       "          168.33333 , 178.66667 ],\n",
       "         [ 73.333336,  68.666664,  69.666664, ..., 150.      ,\n",
       "          182.      , 181.66667 ],\n",
       "         [ 79.      ,  66.      ,  66.333336, ..., 175.33333 ,\n",
       "          183.33333 , 182.66667 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 86.666664,  80.      ,  74.333336, ...,  35.      ,\n",
       "           35.      ,  39.666668],\n",
       "         [ 85.      ,  75.      ,  79.666664, ...,  37.      ,\n",
       "           35.      ,  37.      ],\n",
       "         [ 71.666664,  65.666664,  94.666664, ...,  41.      ,\n",
       "           37.      ,  36.333332],\n",
       "         ...,\n",
       "         [ 92.333336,  88.333336,  87.333336, ...,  66.      ,\n",
       "           79.333336,  94.      ],\n",
       "         [ 86.666664,  86.      ,  88.666664, ...,  46.333332,\n",
       "           58.666668,  64.333336],\n",
       "         [ 77.      ,  78.666664,  81.666664, ...,  44.333332,\n",
       "           50.      ,  44.666668]],\n",
       " \n",
       "        [[ 50.666668,  65.333336,  88.333336, ..., 159.      ,\n",
       "          158.66667 , 152.      ],\n",
       "         [ 60.      ,  83.      ,  99.333336, ..., 157.33333 ,\n",
       "          150.66667 , 149.66667 ],\n",
       "         [ 62.      ,  90.666664,  94.333336, ..., 157.33333 ,\n",
       "          145.      , 143.66667 ],\n",
       "         ...,\n",
       "         [ 60.333332,  61.      ,  62.      , ..., 151.33333 ,\n",
       "          167.      , 164.33333 ],\n",
       "         [ 61.      ,  61.666668,  62.666668, ..., 187.33333 ,\n",
       "          176.33333 , 167.      ],\n",
       "         [ 62.      ,  61.      ,  62.666668, ..., 196.66667 ,\n",
       "          178.66667 , 165.66667 ]],\n",
       " \n",
       "        [[ 30.      ,  27.      ,  33.      , ...,  90.      ,\n",
       "           53.333332,  46.      ],\n",
       "         [ 31.333334,  31.666666,  37.333332, ..., 104.333336,\n",
       "           56.333332,  42.666668],\n",
       "         [ 33.666668,  33.666668,  39.      , ..., 123.333336,\n",
       "           71.333336,  52.333332],\n",
       "         ...,\n",
       "         [ 45.666668,  44.      ,  43.666668, ...,  23.      ,\n",
       "           20.333334,  34.333332],\n",
       "         [ 42.333332,  42.      ,  45.      , ...,  23.666666,\n",
       "           27.      ,  44.      ],\n",
       "         [ 45.333332,  49.666668,  51.333332, ...,  35.      ,\n",
       "           35.666668,  61.      ]]], dtype=float32),\n",
       " 'target': array([5, 6, 3, ..., 5, 3, 5], dtype=int64),\n",
       " 'target_names': array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "        'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], dtype='<U17'),\n",
       " 'DESCR': \".. _labeled_faces_in_the_wild_dataset:\\n\\nThe Labeled Faces in the Wild face recognition dataset\\n------------------------------------------------------\\n\\nThis dataset is a collection of JPEG pictures of famous people collected\\nover the internet, all details are available on the official website:\\n\\n    http://vis-www.cs.umass.edu/lfw/\\n\\nEach picture is centered on a single face. The typical task is called\\nFace Verification: given a pair of two pictures, a binary classifier\\nmust predict whether the two images are from the same person.\\n\\nAn alternative task, Face Recognition or Face Identification is:\\ngiven the picture of the face of an unknown person, identify the name\\nof the person by referring to a gallery of previously seen pictures of\\nidentified persons.\\n\\nBoth Face Verification and Face Recognition are tasks that are typically\\nperformed on the output of a model trained to perform Face Detection. The\\nmost popular model for Face Detection is called Viola-Jones and is\\nimplemented in the OpenCV library. The LFW faces were extracted by this\\nface detector from various online websites.\\n\\n**Data Set Characteristics:**\\n\\n    =================   =======================\\n    Classes                                5749\\n    Samples total                         13233\\n    Dimensionality                         5828\\n    Features            real, between 0 and 255\\n    =================   =======================\\n\\nUsage\\n~~~~~\\n\\n``scikit-learn`` provides two loaders that will automatically download,\\ncache, parse the metadata files, decode the jpeg and convert the\\ninteresting slices into memmapped numpy arrays. This dataset size is more\\nthan 200 MB. The first load typically takes more than a couple of minutes\\nto fully decode the relevant part of the JPEG files into numpy arrays. If\\nthe dataset has  been loaded once, the following times the loading times\\nless than 200ms by using a memmapped version memoized on the disk in the\\n``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\\n\\nThe first loader is used for the Face Identification task: a multi-class\\nclassification task (hence supervised learning)::\\n\\n  >>> from sklearn.datasets import fetch_lfw_people\\n  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n  >>> for name in lfw_people.target_names:\\n  ...     print(name)\\n  ...\\n  Ariel Sharon\\n  Colin Powell\\n  Donald Rumsfeld\\n  George W Bush\\n  Gerhard Schroeder\\n  Hugo Chavez\\n  Tony Blair\\n\\nThe default slice is a rectangular shape around the face, removing\\nmost of the background::\\n\\n  >>> lfw_people.data.dtype\\n  dtype('float32')\\n\\n  >>> lfw_people.data.shape\\n  (1288, 1850)\\n\\n  >>> lfw_people.images.shape\\n  (1288, 50, 37)\\n\\nEach of the ``1140`` faces is assigned to a single person id in the ``target``\\narray::\\n\\n  >>> lfw_people.target.shape\\n  (1288,)\\n\\n  >>> list(lfw_people.target[:10])\\n  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\\n\\nThe second loader is typically used for the face verification task: each sample\\nis a pair of two picture belonging or not to the same person::\\n\\n  >>> from sklearn.datasets import fetch_lfw_pairs\\n  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\\n\\n  >>> list(lfw_pairs_train.target_names)\\n  ['Different persons', 'Same person']\\n\\n  >>> lfw_pairs_train.pairs.shape\\n  (2200, 2, 62, 47)\\n\\n  >>> lfw_pairs_train.data.shape\\n  (2200, 5828)\\n\\n  >>> lfw_pairs_train.target.shape\\n  (2200,)\\n\\nBoth for the :func:`sklearn.datasets.fetch_lfw_people` and\\n:func:`sklearn.datasets.fetch_lfw_pairs` function it is\\npossible to get an additional dimension with the RGB color channels by\\npassing ``color=True``, in that case the shape will be\\n``(2200, 2, 62, 47, 3)``.\\n\\nThe :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\\n3 subsets: the development ``train`` set, the development ``test`` set and\\nan evaluation ``10_folds`` set meant to compute performance metrics using a\\n10-folds cross validation scheme.\\n\\n.. topic:: References:\\n\\n * `Labeled Faces in the Wild: A Database for Studying Face Recognition\\n   in Unconstrained Environments.\\n   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\\n   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\\n   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\\n\\n\\nExamples\\n~~~~~~~~\\n\\n:ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\\n\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2ac917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar tamaño de las imágenes (número de muestras, alto, ancho)\n",
    "# Calcularlo a partir del valor \"images\" del diccionario lfw_people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4387c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar las variables (es decir, las características, no el target)\n",
    "# del conjunto de datos, a su vez, en una variable llamada X.\n",
    "# Para ello, usar el valor \"data\" del diccionario lfw_people.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816b02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar el número de variables del conjunto de datos, \n",
    "# a su vez, en una variable llamada n_features.\n",
    "# Calcular el número de características a partir de X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f751350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar la etiqueta a predecir en una variable llamada y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8715e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar los nombres asociados a los targets en una variable llamada target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e65dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar el número de clases (calculado a partir de la variable anterior, target_names)\n",
    "# en una variable llamada n_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04088830",
   "metadata": {},
   "source": [
    "Si todo ha ido bien, los resultados deben ser los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d9a2a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total dataset size:\")\n",
    "print(f\"n_samples: {n_samples}\")\n",
    "print(f\"n_features: {n_features}\")\n",
    "print(f\"n_classes: {n_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93eb09",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb62014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición en subconjuntos de train (0.75%) y test (0.25%)\n",
    "# Fijar semilla (random_state) en 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46302b",
   "metadata": {},
   "source": [
    "Una vez divididos los datos en dos particiones, efectuar un análisis de componentes principales (*caras propias* o *eigencaras*) para reducir las dimensiones a 150."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6838a9",
   "metadata": {},
   "source": [
    "## Reducción de dimensiones (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf9c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción de las top 150 eigenfaces a partir de 966 caras\n"
     ]
    }
   ],
   "source": [
    "n_components = 150\n",
    "\n",
    "print(f\"Extracción de las top {n_components} eigenfaces a partir de {X_train.shape[0]} caras\")\n",
    "\n",
    "pca = PCA(n_components = n_components, svd_solver= 'randomized', whiten = True).fit(X_train)\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc3354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyectar los datos de entrada sobre la base ortonormal de las eigencaras \n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387e7ef",
   "metadata": {},
   "source": [
    "De ahora en adelante, utilizar X_train_pca para entrenar y X_test_pca para evaluar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00acd3c4",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719b74b",
   "metadata": {},
   "source": [
    "### Primera versión: Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fcc4a0",
   "metadata": {},
   "source": [
    "A continuación, entrenar un clasificador de tipo SVC (Support Vector Classifier) utilizando los datos proyectados sobre la base ortonormal de las eigencaras (variable X_train_pca).\n",
    "\n",
    "Previamente, hacer una búsqueda de hiperparámetros de tipo *Grid* para este clasificador en el siguiente espacio de hiperparámetros:\n",
    "\n",
    "- Valores del hiperparámetro C: 1e3, 5e3, 1e4, 5e4, 1e5.\n",
    "- Valores del hiperparámetro gamma: 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1\n",
    "\n",
    "Utilizar los siguientes hiperparámetros fijos para el clasificador:\n",
    "- kernel de tipo 'rbf'\n",
    "- class_weight de tipo 'balanced'\n",
    "\n",
    "Mostrar el mejor estimador encontrado.\n",
    "\n",
    "***Medir el tiempo que tarda la ejecución de la búsqueda de hiperparámetros, junto al entrenamiento (usar %%time al principio de la celda).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5480744",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167380b4",
   "metadata": {},
   "source": [
    "Una vez conseguido el mejor estimador para este espacio de hiperparámetros, evaluar el modelo en el subconjunto de test. Para ello:\n",
    "- Calcular las predicciones para todo el subconjunto de test y almacenarlas en una variable llamada y_pred.\n",
    "- Mostrar el informe de clasificación para este subconjunto (classification_report)\n",
    "- Mostrar la matriz de confusión para este subconjunto (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05449121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar los resultados en el subconjunto de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfdd97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las imágenes en forma de una galería de retratos\n",
    "def plot_gallery(images, titles, h, w, n_row = 3, n_col = 4):\n",
    "    \n",
    "    \"\"\"Función para crear una galería de retratos\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    \n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "# Componer los títulos, de forma que muestren la etiqueta predicha frente a la real\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    \n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    \n",
    "    return 'Predicted: %s\\nReal:      %s' % (pred_name, true_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218707fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galería de las eigencaras más significativas \n",
    "\n",
    "eigenface_titles = [\"Eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909a062",
   "metadata": {},
   "source": [
    "### Segunda versión: Multilayer Perceptron Classifier (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86841d79",
   "metadata": {},
   "source": [
    "A continuación, entrenar un clasificador de tipo MLP (Multilayer Perceptron Classifier) utilizando los datos proyectados sobre la base ortonormal de las eigencaras (variable X_train_pca).\n",
    "\n",
    "Previamente, hacer una búsqueda de hiperparámetros de tipo Grid para este clasificador en el siguiente espacio de hiperparámetros:\n",
    "\n",
    "- Valores del hiperparámetro hidden_layer_sizes: (10), (10, 10), (10, 10, 10).\n",
    "- Valores del hiperparámetro solver: sgd, adam\n",
    "\n",
    "Utilizar los siguientes hiperparámetros fijos para el clasificador:\n",
    "\n",
    "- Función de activación de tipo 'relu' para las capas ocultas\n",
    "- Shuffle igual a True\n",
    "- Máximo número de iteraciones igual a 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85812c7",
   "metadata": {},
   "source": [
    "***Medir el tiempo que tarda la ejecución de la búsqueda de hiperparámetros, junto al entrenamiento (usar %%time al principio de la celda).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838cd36c",
   "metadata": {},
   "source": [
    "Una vez conseguido el mejor estimador para este espacio de hiperparámetros, evaluar el modelo en el subconjunto de test. Repetir el proceso efectuado para el SVC, mostrando también la galería de imágene de predicciones vs etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7214db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar los resultados en el subconjunto de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6d748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d0c970d",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2de99d",
   "metadata": {},
   "source": [
    "¿Qué conclusiones podrías extraer tras haber entrenado estos dos clasificadores para este conjunto de imágenes? ¿Qué ocurre si bajamos el número de iteraciones máximas a 1000 para el MLP?"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
