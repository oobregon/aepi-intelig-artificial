{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Ventajas-de-la-reducción-de-dimensiones\" data-toc-modified-id=\"Ventajas-de-la-reducción-de-dimensiones-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Ventajas de la reducción de dimensiones</a></span></li><li><span><a href=\"#¿Qué-es-la-maldición-de-la-dimensionalidad?\" data-toc-modified-id=\"¿Qué-es-la-maldición-de-la-dimensionalidad?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>¿Qué es la maldición de la dimensionalidad?</a></span></li><li><span><a href=\"#Técnicas-de-reducción-del-número-de-variables\" data-toc-modified-id=\"Técnicas-de-reducción-del-número-de-variables-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Técnicas de reducción del número de variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Técnicas-de-selección-de-variables\" data-toc-modified-id=\"Técnicas-de-selección-de-variables-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Técnicas de selección de variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Filtro-de-baja-varianza\" data-toc-modified-id=\"Filtro-de-baja-varianza-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Filtro de baja varianza</a></span></li><li><span><a href=\"#Selección-de-variables-univariadas\" data-toc-modified-id=\"Selección-de-variables-univariadas-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Selección de variables univariadas</a></span><ul class=\"toc-item\"><li><span><a href=\"#SelectKBest\" data-toc-modified-id=\"SelectKBest-3.1.2.1\"><span class=\"toc-item-num\">3.1.2.1&nbsp;&nbsp;</span>SelectKBest</a></span></li><li><span><a href=\"#SelectPercentile\" data-toc-modified-id=\"SelectPercentile-3.1.2.2\"><span class=\"toc-item-num\">3.1.2.2&nbsp;&nbsp;</span>SelectPercentile</a></span></li><li><span><a href=\"#SelectFpr\" data-toc-modified-id=\"SelectFpr-3.1.2.3\"><span class=\"toc-item-num\">3.1.2.3&nbsp;&nbsp;</span>SelectFpr</a></span></li><li><span><a href=\"#SelectFdr\" data-toc-modified-id=\"SelectFdr-3.1.2.4\"><span class=\"toc-item-num\">3.1.2.4&nbsp;&nbsp;</span>SelectFdr</a></span></li><li><span><a href=\"#SelectFwe\" data-toc-modified-id=\"SelectFwe-3.1.2.5\"><span class=\"toc-item-num\">3.1.2.5&nbsp;&nbsp;</span>SelectFwe</a></span></li><li><span><a href=\"#GenericUnivariateSelect\" data-toc-modified-id=\"GenericUnivariateSelect-3.1.2.6\"><span class=\"toc-item-num\">3.1.2.6&nbsp;&nbsp;</span>GenericUnivariateSelect</a></span></li></ul></li><li><span><a href=\"#Eliminación-de-características-de-forma-recursiva\" data-toc-modified-id=\"Eliminación-de-características-de-forma-recursiva-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Eliminación de características de forma recursiva</a></span></li><li><span><a href=\"#Selección-de-características-basadas-en-árboles\" data-toc-modified-id=\"Selección-de-características-basadas-en-árboles-3.1.4\"><span class=\"toc-item-num\">3.1.4&nbsp;&nbsp;</span>Selección de características basadas en árboles</a></span></li></ul></li><li><span><a href=\"#Técnicas-de-reducción-de-dimensionalidad\" data-toc-modified-id=\"Técnicas-de-reducción-de-dimensionalidad-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Técnicas de reducción de dimensionalidad</a></span><ul class=\"toc-item\"><li><span><a href=\"#Análisis-de-componentes-principales-(PCA)\" data-toc-modified-id=\"Análisis-de-componentes-principales-(PCA)-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Análisis de componentes principales (PCA)</a></span></li><li><span><a href=\"#Análisis-de-discriminante-lineal-(LDA)\" data-toc-modified-id=\"Análisis-de-discriminante-lineal-(LDA)-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Análisis de discriminante lineal (LDA)</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La reducción de la dimensionalidad es una de las técnicas básicas de preprocesado de datos, que consiste en la reducción del número de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ventajas de la reducción de dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori, puede parecer que cuanta más información, mejor. Sin embargo, en la mayoría de los casos no es así. De hecho, hay varias razones por las que puede ser interesante tratar de reducir el número de dimensiones del conjunto de datos:\n",
    "- Se reduce la complejidad, con lo que el modelo y sus resultados se hacen más fácilmente interpretables.\n",
    "- Por razones de ahorro, tanto en coste como en tiempo. Reduciendo las dimensiones, se mejora el rendimiento computacional.\n",
    "- Se identifican y eliminan las variables irrelevantes, reduciendo el ruido del dataset original. Es importante tener en cuenta que, en ocasiones, el mejor modelo posible no es el que tiene en cuenta más variables, sino aquel que incluye únicamente la información \"de calidad\". Aquí entra en juego la *Maldición de la dimensionalidad*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es la maldición de la dimensionalidad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, un modelo de Machine Learning requiere una información abundante al principio, con el fin de realizar predicciones más precisas. Sin embargo, llegado a cierto punto, el rendimiento del modelo disminuirá conforme aumente el número de variables. Este fenómeno es lo que se conoce como \"maldición de la dimensionalidad”.\n",
    "\n",
    "La maldición de la dimensionalidad tiene lugar porque, al aumentar el número de variables y mantenerse el mismo número de muestras, la densidad de la muestra disminuye exponencialmente, volviéndose cada vez más dispersa. A partir de una muestra dispersa, el modelo de Machine Learning posiblemente obtendrá una solución que, aparentemente, sea muy buena. Sin embargo, lo que estará sucediendo en realidad es que se habrá producido un sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de reducción del número de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En líneas generales, se puede establecer la siguiente clasificación de técnicas de reducción del número de variables:\n",
    "- Selección de variables: filtro de baja varianza, pruebas estadísticas univariadas, eliminación de características de forma recursiva, bosques aleatorios, ratio de valores faltantes, filtro de alta correlación,  etc.\n",
    "- Reducción de dimensionalidad:\n",
    "    - Lineal: análisis factorial, análisis de componentes principales (PCA), análisis de discriminante lineal.\n",
    "    - No lineal: escala multidimensional, mapeo de características isométricas, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de baja varianza\n",
    "Elimina las variables cuya varianza no alcanza un cierto umbral. De forma predeterminada, descarta todas las características de varianza cero, es decir, las características que tienen el mismo valor en todas las muestras. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables univariadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas técnicas seleccionan las mejores variables basándose en pruebas estadísticas univariadas. Toman como entrada una función de puntuación que, en general, puede ser:\n",
    "- Para tareas de regresión: f_regression, mutual_info_regression\n",
    "- Para tareas de clasificación: chi2, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest\n",
    "Elimina todo menos las k características con puntuaciones más altas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectPercentile\n",
    "Elimina todas las características excepto el porcentaje de variables (especificado por el usuario) que tengan puntuación más alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFpr\n",
    "Tasa de falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFdr\n",
    "Tasa de descubrimiento falso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFwe\n",
    "Error familiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GenericUnivariateSelect\n",
    "Realiza una selección de características univariadas con una estrategia configurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**\n",
    "Si los datos son dispersos (sparse), las funciones *chi2, mutual_info_regression* y *mutual_info_classif* responderán bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de características de forma recursiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica consiste en seleccionar grupos de características cada vez más pequeños. Primero, se entrena un estimador con todas las variables y se obtiene la importancia de cada una de ellas. Después, las menos importantes se eliminan y se vuelve a repetir el procedimiento hasta que se alcanza el número deseado de variables finales.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de características basadas en árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisión se pueden utilizar para calcular la importancia de las variables, por lo que se pueden usar para descartar variables irrelevantes (combinando el estimador basado en árboles de decisión con el método SelectFromModel de Scikit Learn, por ejemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de componentes principales (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de discriminante lineal (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "    \n",
    "https://scikit-learn.org/stable/modules/lda_qda.html#lda-qda"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
