{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras - Taller de refuerzo (II) - Without_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUlHuSPjrp5J"
      },
      "source": [
        "# Taller de refuerzo de Keras (II)\n",
        "\n",
        "En este taller, realizaremos los pasos necesarios para construir una red neuronal convolucional (CNN) 3D para predecir la presencia de neumonía viral en tomografías computarizadas (TC). Las CNN 2D se utilizan comúnmente para procesar imágenes RGB (3 canales). Una CNN 3D es simplemente el equivalente en 3D: toma como entrada un volumen 3D o una secuencia de cuadros 2D (por ejemplo, cortes en una tomografía computarizada). Sin duda, las CNN 3D son un modelo poderoso para aprender representaciones de datos volumétricos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-9MuRkSrhF6"
      },
      "source": [
        "## Carga de librerías, módulos y funciones\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBUiF7_8rIBJ"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import nibabel as nib\n",
        "\n",
        "from scipy import ndimage\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iOGCx5Srz0p"
      },
      "source": [
        "## Carga de datos y preprocesamiento\n",
        "\n",
        "Usaremos un subconjunto de MosMedData que consta de tomografías computarizadas de pulmón con hallazgos relacionados con COVID-19, así como algunas sin tales hallazgos.\n",
        "\n",
        "Usaremos los hallazgos radiológicos asociados de las tomografías computarizadas como etiquetas para construir un clasificador para predecir la presencia de neumonía viral. Por tanto, la tarea es un problema de clasificación binaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1UQXZJ32dee"
      },
      "source": [
        "### Descarga de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxLljlkAqJ59",
        "outputId": "591bd88e-8a39-4e20-a985-3504f167369a"
      },
      "source": [
        "# # Download url of normal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "# Download url of abnormal CT scans.\n",
        "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
        "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
        "keras.utils.get_file(filename, url)\n",
        "\n",
        "if not os.path.exists(\"MosMedData\"):\n",
        "  # Make a directory to store the data.\n",
        "  os.makedirs(\"MosMedData\")\n",
        "\n",
        "  # Unzip data in the newly created directory.\n",
        "  with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
        "      z_fp.extractall(\"./MosMedData/\")\n",
        "\n",
        "  with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
        "      z_fp.extractall(\"./MosMedData/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\n",
            "1065476096/1065471431 [==============================] - 37s 0us/step\n",
            "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\n",
            "1045168128/1045162547 [==============================] - 95s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exSTpaFp2lG6"
      },
      "source": [
        "### Procesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5btz0CHVsvVF"
      },
      "source": [
        "Para procesar los datos, hacemos lo siguiente:\n",
        "\n",
        "- Primero giramos los volúmenes 90 grados, por lo que la orientación es fija.\n",
        "- Escalamos algunos valores para que estén entre 0 y 1.\n",
        "- Redimensionamos ancho, alto y profundidad.\n",
        "\n",
        "\n",
        "Para ello, definimos varias funciones auxiliares de procesamiento de datos. Estas funciones se utilizarán al crear conjuntos de datos de entrenamiento y evaluación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddIPCrRDrOa-"
      },
      "source": [
        "def read_nifti_file(filepath):\n",
        "    \"\"\"Read and load volume\"\"\"\n",
        "    # Read file\n",
        "    scan = nib.load(filepath)\n",
        "    # Get raw data\n",
        "    scan = scan.get_fdata()\n",
        "    return scan\n",
        "\n",
        "\n",
        "def normalize(volume):\n",
        "    \"\"\"Normalize the volume\"\"\"\n",
        "    min = -1000\n",
        "    max = 400\n",
        "    volume[volume < min] = min\n",
        "    volume[volume > max] = max\n",
        "    volume = (volume - min) / (max - min)\n",
        "    volume = volume.astype(\"float32\")\n",
        "    return volume\n",
        "\n",
        "\n",
        "def resize_volume(img):\n",
        "    \"\"\"Resize across z-axis\"\"\"\n",
        "    # Set the desired depth\n",
        "    desired_depth = 64\n",
        "    desired_width = 128\n",
        "    desired_height = 128\n",
        "    # Get current depth\n",
        "    current_depth = img.shape[-1]\n",
        "    current_width = img.shape[0]\n",
        "    current_height = img.shape[1]\n",
        "    # Compute depth factor\n",
        "    depth = current_depth / desired_depth\n",
        "    width = current_width / desired_width\n",
        "    height = current_height / desired_height\n",
        "    depth_factor = 1 / depth\n",
        "    width_factor = 1 / width\n",
        "    height_factor = 1 / height\n",
        "    # Rotate\n",
        "    img = ndimage.rotate(img, 90, reshape=False)\n",
        "    # Resize across z-axis\n",
        "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_scan(path):\n",
        "    \"\"\"Read and resize volume\"\"\"\n",
        "    # Read scan\n",
        "    volume = read_nifti_file(path)\n",
        "    # Normalize\n",
        "    volume = normalize(volume)\n",
        "    # Resize width, height and depth\n",
        "    volume = resize_volume(volume)\n",
        "    return volume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJyWSYdwtC6R"
      },
      "source": [
        "A continuación, leemos las rutas de los escaneos CT de los directorios de clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YYe1XU5tG8u",
        "outputId": "588c9fbc-8be9-4300-b9a9-629d24df26da"
      },
      "source": [
        "# La carpeta \"CT-0\" consta de tomografías computarizadas que tienen tejido pulmonar normal,\n",
        "# es decir, no hay signos de neumonía viral en la TC.\n",
        "normal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-0\")\n",
        "]\n",
        "# La carpeta \"CT-23\" consta de tomografías computarizadas que tienen varias zonas con distinta apariencia,\n",
        "# es decir, presentan afectación del pulmón.\n",
        "abnormal_scan_paths = [\n",
        "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
        "    for x in os.listdir(\"MosMedData/CT-23\")\n",
        "]\n",
        "\n",
        "print(\"CTs con tejido normal de pulmón: \" + str(len(normal_scan_paths)))\n",
        "print(\"CTs con tejido anormal de pulmón: \" + str(len(abnormal_scan_paths)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CTs con tejido normal de pulmón: 100\n",
            "CTs con tejido anormal de pulmón: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2M3vFQXtXun"
      },
      "source": [
        "- Leeremos ahora los escaneos de los directorios de clases y asignaremos etiquetas. \n",
        "- Además, dividiremos el conjunto de datos en subconjuntos de train y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfv74iAtzJ2"
      },
      "source": [
        "# Lectura de escáneres\n",
        "# Resize\n",
        "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
        "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0wSqpgJt4Vu"
      },
      "source": [
        "# Para los CTs con presencia de virus de neumonía\n",
        "# crea una variable llamada abnormal_labels que contenga\n",
        "# etiquetas con valor 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH3dVuEduOxM"
      },
      "source": [
        "# Para los CTs sin presencia de virus de neumonía\n",
        "# crea una variable llamada normal_labels que contenga\n",
        "# etiquetas con valor 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V5AIg5Jx4Z3"
      },
      "source": [
        "# Concatena abnormal_scans y normal_scans con np.concatenate()\n",
        "# La variable resultante debe llamarse scans\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJfSHxoVyIDt"
      },
      "source": [
        "# Concatena abnormal_labels y normal_labels con np.concatenate()\n",
        "# La variable resultante debe llamarse labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHyaBNeH2pNy"
      },
      "source": [
        "### Particiones de entrenamiento y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlRxd9MxupL-"
      },
      "source": [
        "# Crea una partición de train (70% de los datos) y otra de test (30%)\n",
        "# Fija una semilla de 42 para garantizar la repetibilidad de los resultados\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P1uRot8ye_P",
        "outputId": "1feec0cb-ca8b-417a-fe0f-9ddf81a53f13"
      },
      "source": [
        "# Comprueba que los resultados obtenidos son los siguientes:\n",
        "print(f\"Hay {X_train.shape[0]} muestras de entrenamiento y {X_test.shape[0]} muestras de test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hay 140 muestras de entrenamiento y 60 muestras de test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FACJc-n2tgU"
      },
      "source": [
        "### Visualización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iyrL1t4-k91"
      },
      "source": [
        "# Muestra una de las imágenes de entrenamiento\n",
        "image = X_train[0]\n",
        "\n",
        "print(\"Dimensiones:\", image.shape)\n",
        "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmLEB6_M2wC8"
      },
      "source": [
        "Dado que una tomografía computarizada tiene muchos cortes, visualicemos un montaje de los cortes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRU37u-P-nM9"
      },
      "source": [
        "# Ejecuta esta celda para mostrar los gráficos\n",
        "def plot_slices(num_rows, num_columns, width, height, data):\n",
        "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
        "    data = np.rot90(np.array(data))\n",
        "    data = np.transpose(data)\n",
        "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
        "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
        "    heights = [slc[0].shape[0] for slc in data]\n",
        "    widths = [slc.shape[1] for slc in data[0]]\n",
        "    fig_width = 12.0\n",
        "    fig_height = fig_width * sum(heights) / sum(widths)\n",
        "    f, axarr = plt.subplots(\n",
        "        rows_data,\n",
        "        columns_data,\n",
        "        figsize=(fig_width, fig_height),\n",
        "        gridspec_kw={\"height_ratios\": heights},\n",
        "    )\n",
        "    for i in range(rows_data):\n",
        "        for j in range(columns_data):\n",
        "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
        "            axarr[i, j].axis(\"off\")\n",
        "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
        "    plt.show()\n",
        "\n",
        "# 4 filas y 10 columnas para 100 slices del escáner CT\n",
        "plot_slices(4, 10, 128, 128, image[:, :, :40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQoNGB7k_jmn"
      },
      "source": [
        "### Cargadores de datos para alimentar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGxWQRAl_mqs"
      },
      "source": [
        "# Data loaders\n",
        "train_loader = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "validation_loader = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD1nqPHZAyb1"
      },
      "source": [
        "Dado que los datos se almacenan en tensores de forma de rango 3 (samples, height, width, depth), agregamos una dimensión de tamaño 1 en el eje 4 para poder realizar convoluciones 3D en los datos. La nueva forma es así (samples, height, width, depth, 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdwCOZTuAwN9"
      },
      "source": [
        "def add_dimension(volume, label):\n",
        "    \"\"\" Añadimos una dimensión adicional \"\"\"\n",
        "    volume = tf.expand_dims(volume, axis=3)\n",
        "    return volume, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94tbQ7_JA3-0"
      },
      "source": [
        "batch_size = 2\n",
        "\n",
        "# Aplicamos el tamaño de batch, \n",
        "train_dataset = (train_loader.shuffle(len(X_train))\n",
        "    .map(add_dimension)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")\n",
        "\n",
        "validation_dataset = (\n",
        "    validation_loader.shuffle(len(X_test))\n",
        "    .map(add_dimension)\n",
        "    .batch(batch_size)\n",
        "    .prefetch(2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg1gs93A3EVK"
      },
      "source": [
        "## Definición de una red neuronal convolucional 3D\n",
        "\n",
        "Para que el modelo sea más fácil de entender, lo estructuraremos en bloques. La arquitectura de la CNN 3D utilizada en este ejemplo se basa en este documento: https://arxiv.org/abs/2007.13224\n",
        "\n",
        "El modelo se llamará 3D_CNN y estará compuesta por:\n",
        "\n",
        "- Bloque 1:\n",
        "  - Una capa Conv3D con 64 filtros de salida en la convolución, tamaño 3 de kernel y activación ReLu. Recuerda que, al ser la primera capa, requiere que se especifique el tamaño de entrada de los datos.\n",
        "  - Una operación de MaxPool3D (que se introduce como una capa adicional de Keras), con tamaño 2 de pool.\n",
        "\n",
        "- Bloque 2:\n",
        "  - Una operación de BatchNormalization (que también se introduce como una capa adicional de Keras).\n",
        "  - Una capa Conv3D con 64 filtros de salida en la convolución, tamaño 3 de kernel y activación ReLu.\n",
        "  - Una operación de MaxPool3D (que se introduce como una capa adicional de Keras), con tamaño 2 de pool.\n",
        "\n",
        "- Bloque 3\n",
        "  - Una operación de BatchNormalization (que también se introduce como una capa adicional de Keras).\n",
        "  - Una capa Conv3D con 128 filtros de salida en la convolución, tamaño 3 de kernel y activación ReLu.\n",
        "  - Una operación de MaxPool3D (que se introduce como una capa adicional de Keras), con tamaño 2 de pool.\n",
        "\n",
        "- Bloque 4\n",
        "  - Una operación de BatchNormalization (que también se introduce como una capa adicional de Keras).\n",
        "  - Una capa Conv3D con 256 filtros de salida en la convolución, tamaño 3 de kernel y activación ReLu.\n",
        "  - Una operación de MaxPool3D (que se introduce como una capa adicional de Keras), con tamaño 2 de pool.\n",
        "\n",
        "- Bloque 5\n",
        "  - Una operación de BatchNormalization (que también se introduce como una capa adicional de Keras).\n",
        "  - Una operación de GlobalAveragePooling3D (que también se introduce como una capa adicional de Keras).\n",
        "  - Una capa densa de 512 unidades y activación ReLu.\n",
        "  - Una operación de Dropout (que también se introduce como una capa adicional de Keras), con ratio 0.3.\n",
        "\n",
        "- Capa de salida de tipo Denso, con una cantidad de neuronas y una función de activación apropiadas para este tipo de problema.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFsiEDh__zRA"
      },
      "source": [
        "### Batch normalization\n",
        "La normalización es una categoría amplia de métodos que buscan hacer que las diferentes muestras vistas por un modelo de aprendizaje automático sean más similares entre sí, lo que ayuda al modelo a aprender y generalizar bien a nuevos datos. La forma más común de normalización de datos consiste en centrar los datos en cero restando la media de los datos y dar a los datos una desviación estándar unitaria dividiendo los datos por su desviación estándar. En efecto, esto supone que los datos siguen una distribución normal (o gaussiana) y asegura que esta distribución esté centrada y escalada a la varianza de la unidad.\n",
        "\n",
        "`normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)`\n",
        "\n",
        "Es habitual normalizar los datos antes de introducirlos en una red neuronal. Pero esto solo tiene efecto en la primera capa, ya que la normalización de los datos puede perderse después de cada transformación operada por la red: incluso si los datos que se introducen a una red Dense o Conv2D tienen una media de 0 y una varianza unitaria, no hay razón para esperar a priori que este sea el caso de los datos que salen. Para solucionar esto, se utiliza la normalización de las activaciones intermedias o normalización por lotes (\"capa\" BatchNormalization en Keras)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a-N1Mos3U1t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep0WOsdo6Hbi"
      },
      "source": [
        "# Muestra el modelo con el método summary()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7ItrquI6swu"
      },
      "source": [
        "## Compilación del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c38neyM6yS8"
      },
      "source": [
        "# Compila el modelo anterior, utilizando una pérdida, un optimizador y una\n",
        "# métrica de monitorización que consideres apropiados para este problema\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8HhLriT7Lke"
      },
      "source": [
        "## Ajuste del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcWQOEpt7QuO"
      },
      "source": [
        "# Define un callback para guardar el modelo \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQY8Hiap7YH7"
      },
      "source": [
        "# Define un callback de early stopping que monitoree el accuracy de validación \n",
        "# y tenga paciencia máxima para 15 epochs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h_eoIni7NHO"
      },
      "source": [
        "# Ajusta el modelo, realizando una validación al final de capa epoch\n",
        "# Fija el número de epochs máximas en 100\n",
        "# Aplica shuffle a los datos\n",
        "# Fija la verbosidad en 2\n",
        "# Aplica los callbacks definidos en las celdas anteriores\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQWJZo0E8BRF"
      },
      "source": [
        "## Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6BimZaf-gK-"
      },
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
        "ax = ax.ravel()\n",
        "\n",
        "for i, metric in enumerate([\"accuracy\", \"loss\"]):\n",
        "    ax[i].plot(model.history.history[metric])\n",
        "    ax[i].plot(model.history.history[\"validation_\" + metric])\n",
        "    ax[i].set_title(\"Model {}\".format(metric))\n",
        "    ax[i].set_xlabel(\"epochs\")\n",
        "    ax[i].set_ylabel(metric)\n",
        "    ax[i].legend([\"train\", \"val\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twH8CfKs8KSM"
      },
      "source": [
        "## Predicción"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HdJb0TOK8Lzm"
      },
      "source": [
        "# Carga los mejores pesos del modelo\n",
        "model.load_weights(\"3d_image_classification.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IHvicVGM8Q-k"
      },
      "source": [
        "# Realiza predicciones para el dataset de test\n",
        "# Para ello, ejecuta esta celda\n",
        "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
        "scores = [1 - prediction[0], prediction[0]]\n",
        "\n",
        "class_names = [\"normal\", \"anormal\"]\n",
        "for score, name in zip(scores, class_names):\n",
        "    print(\n",
        "        \"Este modelo tiene una confianza del %.2f % de que este escáner CT es %s\"\n",
        "        % ((100 * score), name)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM2jCuNq8nYy"
      },
      "source": [
        "## Ampliaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ0-D5MyCK_E"
      },
      "source": [
        "### Primer experimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgPrZ7m7udkH"
      },
      "source": [
        "A continuación, aplicaremos la técnica de Data Augmentation. Para ello, existen varias opciones, de las cuales optaremos por la que consiste en aplicar técnicas de variación de imágenes a modo de capas de preprocesamiento dentro de un modelo secuencial de Keras.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "`data_augmentation = Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])`\n",
        "\n",
        "\n",
        "En este caso, RandomFlip voltea aleatoriamente cada imagen horizontal y verticalmente, mientras que RandomRotation la rota aleatoriamente en base a una fracción de 2pi en sentido antihorario (consultar documentación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoJjsHtu9Yys"
      },
      "source": [
        "A continuación, se podría añadir este pequeño modelo a otro modelo secuencial, tal y como se muestra a continuación:\n",
        "\n",
        "`model = tf.keras.Sequential([`\n",
        "\n",
        "  `resize_and_rescale,`\n",
        "\n",
        "  `data_augmentation,`\n",
        "\n",
        "  `layers.Conv2D(16, 3, padding='same', activation='relu'),`\n",
        "\n",
        "  `layers.MaxPooling2D(),`\n",
        "\n",
        "  `# Resto del modelo`\n",
        "\n",
        "`])`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbV-07Ht14to"
      },
      "source": [
        "Ahora, puedes continuar definir un nuevo modelo replicando la arquitectura del modelo que utilizamos en el caso de uso anterior y añadiendo capas de preprocesamiento al principio, con el fin de aplicar la técnica de Data Augmentation. Llámale 3D_CNN_DA, entrénalo y evalúalo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2ehe5cy9Qen"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcC2qD9kCONe"
      },
      "source": [
        "### Segundo experimento\n",
        "\n",
        "Explora la clase ImageDataGenerator de Keras, que genera lotes de datos de imágenes de tensores con aplicación de data augmentation en tiempo real."
      ]
    }
  ]
}