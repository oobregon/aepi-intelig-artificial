{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2536d62",
   "metadata": {},
   "source": [
    "# Computer Vision: entrenamiento de un clasificador de imágenes en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1300131",
   "metadata": {},
   "source": [
    "Para aplicaciones de Computer Vision, PyTorch dispone de un paquete llamado *torchvision*, que tiene cargadores de datos para conjuntos de datos comunes como Imagenet, CIFAR10, MNIST, etc. y transformadores de datos para imágenes (*torchvision.datasets* y *torch.utils.data.DataLoader*).\n",
    "\n",
    "Esto proporciona una gran comodidad y evita escribir código repetitivo.\n",
    "\n",
    "Para esta práctica, se va a utilizar el conjunto de datos CIFAR10, el cual incluye imágenes de las siguientes clases: 'avión', 'automóvil', 'pájaro', 'gato', 'ciervo', 'perro', 'rana', 'caballo', 'barco', 'camión'. \n",
    "\n",
    "*En inglés: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’*.\n",
    "\n",
    "Las imágenes en CIFAR-10 son de dimensiones 3x32x32, es decir, imágenes en color de 3 canales de 32x32 píxeles de tamaño.\n",
    "\n",
    "\n",
    "Realizaremos los siguientes pasos:\n",
    "\n",
    "- Carga y normalización de los conjuntos de datos de prueba y entrenamiento CIFAR10 usando torchvision.\n",
    "- Definición de una red neuronal convolucional.\n",
    "- Definición de una función de pérdida.\n",
    "- Entrenamiento de la red con los datos de entrenamiento.\n",
    "- Prueba de la red entranada en los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528529ba",
   "metadata": {},
   "source": [
    "## Carga y normalización de CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f3e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d56e214",
   "metadata": {},
   "source": [
    "La salida de los conjuntos de datos de torchvision son imágenes PIL de rango [0, 1]. \n",
    "\n",
    "Por su parte, transforms.ToTensor() permite convertir una imagen PIL o numpy.ndarray (H x W x C) con valores de píxel en el rango [0, 255] a un torch.FloatTensor de dimensiones (C x H x W) en el rango [0.0, 1.0].\n",
    "\n",
    "Para normalizarlos, utilizamos*transforms.Normalize()* especificando [-1, 1].\n",
    "\n",
    "(https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7852c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 medias y 3 desviaciones estándar para los 3 canales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e743c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6f24c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/vision/stable/datasets.html#torchvision.datasets.CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d128f",
   "metadata": {},
   "source": [
    "## Definición de una red neuronal convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f2dfb3",
   "metadata": {},
   "source": [
    "Hiperparámetros de las capas que se van a usar:\n",
    "\n",
    "- torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "- torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "\n",
    "- torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71599cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2aa4b0c",
   "metadata": {},
   "source": [
    "## Definición de una función de pérdida y un optimizador\n",
    "Usaremos una pérdida de clasificación de entropía cruzada y SGD con momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5f66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14aefa0",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red\n",
    "Tenemos que ir alimentando al iterador de datos, introduciendo las entradas a la red, y realizar el proceso de optimización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460edb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719c951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcado del modelo entrenado en un archivo .pth (4D Path Document)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33047e",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00e942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b7551dd",
   "metadata": {},
   "source": [
    "Las salidas son *energías* para las 10 clases. Cuanto mayor es la energía de una clase, más piensa la red que la imagen es de esa clase en particular. Entonces, lo que tenemos que hacer es extraer el índice de la energía más alta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480da099",
   "metadata": {},
   "source": [
    "Veamos cómo funciona la red en todo el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e77187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c6c99cd",
   "metadata": {},
   "source": [
    "El accuracy ronda el 54%, lo que es bastante mejor que el azar, que es un 10% de precisión (elegir al azar una clase de 10 posibles). Parece que la red aprendió algo.\n",
    "\n",
    "Comprobemos ahora cuáles son las clases que funcionan bien y cuáles son las que lo hacen peor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622c195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae6178a",
   "metadata": {},
   "source": [
    "## Bonus: ¿cómo entrenar en GPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef8388",
   "metadata": {},
   "source": [
    "Primero definimos nuestro dispositivo como el primer dispositivo cuda visible si tenemos CUDA disponible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b382cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Si tenemos CUDA, se debería mostrar un dispositivo CUDA:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc1a003",
   "metadata": {},
   "source": [
    "Asumiendo que, en efecto, el dispositivo es CUDA, los siguientes métodos revisarán recursivamente todos los módulos y convertirán sus parámetros y búferes en tensores CUDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27809c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65dc45",
   "metadata": {},
   "source": [
    "También tenemos que enviar las entradas y los objetivos en cada paso a la GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8bf610",
   "metadata": {},
   "source": [
    "¿Por qué no se nota una aceleración realmente significativa en comparación con la CPU? Porque la red es realmente pequeña."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb80ed",
   "metadata": {},
   "source": [
    "Ejercicio: intenta aumentar el ancho de la red (segundo argumento de la primera capa nn.Conv2d y primer argumento de la segunda nn.Conv2d; que deben ser el mismo número). Observa cómo se acelera el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe688b",
   "metadata": {},
   "source": [
    "Si se desea ver una aceleración aún más masiva usando todas las GPUs disponibles, consultar la siguiente sección de PyTorch: https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
